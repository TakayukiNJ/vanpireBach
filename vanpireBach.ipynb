{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vanpireBach.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvm0uTlq9EylUkqicWGSXC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TakayukiNJ/vanpireBach/blob/main/vanpireBach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7gAkKsfTIuO"
      },
      "outputs": [],
      "source": [
        "# ライブラリのインストール https://colab.research.google.com/notebooks/magenta/hello_magenta/hello_magenta.ipynb\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "!pip install -qU magenta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ライブラリの導入 (GANSynthは音色を変えるAI) https://colab.research.google.com/notebooks/magenta/gansynth/gansynth_demo.ipynb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import tensorflow.compat.v1 as tf\n",
        "import librosa\n",
        "\n",
        "import magenta.music as mm\n",
        "from magenta.models.gansynth.lib import flags as lib_flags\n",
        "from magenta.models.gansynth.lib import generate_util as gu\n",
        "from magenta.models.gansynth.lib import model as lib_model\n",
        "from magenta.models.gansynth.lib import util\n",
        "from note_seq.notebook_utils import colab_play as play\n",
        "\n",
        "import note_seq"
      ],
      "metadata": {
        "id": "xpoaaIDtTXYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 曲生成の設定\n",
        "BATCH_SIZE = 16  # 一度に扱うデータ数\n",
        "SR = 16000  # サンプリングレート\n",
        "\n",
        "# 音声を処理する関数\n",
        "def load_midi(midi_path, min_pitch=36, max_pitch=84):\n",
        "  \"\"\"Load midi as a notesequence.\"\"\"\n",
        "  midi_path = util.expand_path(midi_path)\n",
        "  ns = note_seq.midi_file_to_sequence_proto(midi_path)\n",
        "  pitches = np.array([n.pitch for n in ns.notes])\n",
        "  velocities = np.array([n.velocity for n in ns.notes])\n",
        "  start_times = np.array([n.start_time for n in ns.notes])\n",
        "  end_times = np.array([n.end_time for n in ns.notes])\n",
        "  valid = np.logical_and(pitches >= min_pitch, pitches <= max_pitch)\n",
        "  notes = {'pitches': pitches[valid],\n",
        "           'velocities': velocities[valid],\n",
        "           'start_times': start_times[valid],\n",
        "           'end_times': end_times[valid]}\n",
        "  return ns, notes\n",
        "\n",
        "def get_envelope(t_note_length, t_attack=0.010, t_release=0.3, sr=16000):\n",
        "  \"\"\"Create an attack sustain release amplitude envelope.\"\"\"\n",
        "  t_note_length = min(t_note_length, 3.0)\n",
        "  i_attack = int(sr * t_attack)\n",
        "  i_sustain = int(sr * t_note_length)\n",
        "  i_release = int(sr * t_release)\n",
        "  i_tot = i_sustain + i_release  # attack envelope doesn't add to sound length\n",
        "  envelope = np.ones(i_tot)\n",
        "  # Linear attack\n",
        "  envelope[:i_attack] = np.linspace(0.0, 1.0, i_attack)\n",
        "  # Linear release\n",
        "  envelope[i_sustain:i_tot] = np.linspace(1.0, 0.0, i_release)\n",
        "  return envelope\n",
        "\n",
        "def combine_notes(audio_notes, start_times, end_times, velocities, sr=16000):\n",
        "  \"\"\"Combine audio from multiple notes into a single audio clip.\n",
        "\n",
        "  Args:\n",
        "    audio_notes: Array of audio [n_notes, audio_samples].\n",
        "    start_times: Array of note starts in seconds [n_notes].\n",
        "    end_times: Array of note ends in seconds [n_notes].\n",
        "    sr: Integer, sample rate.\n",
        "\n",
        "  Returns:\n",
        "    audio_clip: Array of combined audio clip [audio_samples]\n",
        "  \"\"\"\n",
        "  n_notes = len(audio_notes)\n",
        "  clip_length = end_times.max() + 3.0\n",
        "  audio_clip = np.zeros(int(clip_length) * sr)\n",
        "\n",
        "  for t_start, t_end, vel, i in zip(start_times, end_times, velocities, range(n_notes)):\n",
        "    # Generate an amplitude envelope\n",
        "    t_note_length = t_end - t_start\n",
        "    envelope = get_envelope(t_note_length)\n",
        "    length = len(envelope)\n",
        "    audio_note = audio_notes[i, :length] * envelope\n",
        "    # Normalize\n",
        "    audio_note /= audio_note.max()\n",
        "    audio_note *= (vel / 127.0)\n",
        "    # Add to clip buffer\n",
        "    clip_start = int(t_start * sr)\n",
        "    clip_end = clip_start + length\n",
        "    audio_clip[clip_start:clip_end] += audio_note\n",
        "\n",
        "  # Normalize\n",
        "  audio_clip /= audio_clip.max()\n",
        "  audio_clip /= 2.0\n",
        "  return audio_clip\n",
        "\n",
        "# Plotting tools\n",
        "def specplot(audio_clip):\n",
        "  p_min = np.min(36)\n",
        "  p_max = np.max(84)\n",
        "  f_min = librosa.midi_to_hz(p_min)\n",
        "  f_max = 2 * librosa.midi_to_hz(p_max)\n",
        "  octaves = int(np.ceil(np.log2(f_max) - np.log2(f_min)))\n",
        "  bins_per_octave = 36\n",
        "  n_bins = int(bins_per_octave * octaves)\n",
        "  C = librosa.cqt(audio_clip, sr=SR, hop_length=2048, fmin=f_min, n_bins=n_bins, bins_per_octave=bins_per_octave)\n",
        "  power = 10 * np.log10(np.abs(C)**2 + 1e-6)\n",
        "  plt.matshow(power[::-1, 2:-2], aspect='auto', cmap=plt.cm.magma)\n",
        "  plt.yticks([])\n",
        "  plt.xticks([])"
      ],
      "metadata": {
        "id": "n4k1RvwZTcGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習済みモデルを読み込み\n",
        "tf.disable_v2_behavior()  # tensorflow2で1.xのコードを動かす\n",
        "tf.reset_default_graph()  # tensorflowのグラフをリセット\n",
        "\n",
        "model_dir = \"gs://magentadata/models/gansynth/acoustic_only\"\n",
        "flags = lib_flags.Flags({\n",
        "    \"batch_size_schedule\": [BATCH_SIZE],\n",
        "    \"tfds_data_dir\": \"gs://tfds-data/datasets\",\n",
        "})\n",
        "model = lib_model.Model.load_from_path(model_dir, flags)"
      ],
      "metadata": {
        "id": "BdYrL7RVTeWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ファイルの読み込み（ヴァンパイアのMIDIファイルをダウンロードして、colabにアップロードしてください）　https://otoiro.co.jp/special/\n",
        "midi_path = \"/content/Vampire_Melo_164BPM.mid\"\n",
        "ns, notes = load_midi(midi_path)\n",
        "\n",
        "note_seq.plot_sequence(ns)\n",
        "note_seq.play_sequence(ns, synth=note_seq.fluidsynth) "
      ],
      "metadata": {
        "id": "7_cjVeMoTuCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 音色を変更 https://youtu.be/cjNFTLG4EUQ\n",
        "seconds_per_instrument = 5  # 楽器が切り替わる間隔\n",
        "\n",
        "# 潜在変数がランダムにゆっくりと変化\n",
        "z_instruments, t_instruments = gu.get_random_instruments(  # 潜在変数とその時間\n",
        "    model,\n",
        "    notes[\"end_times\"][-1],\n",
        "    secs_per_instrument=seconds_per_instrument)\n",
        "\n",
        "# 各noteの潜在変数を取得\n",
        "z_notes = gu.get_z_notes(notes[\"start_times\"], z_instruments, t_instruments)\n",
        "\n",
        "# 各ノートの音声を生成\n",
        "audio_notes = model.generate_samples_from_z(z_notes, notes[\"pitches\"])\n",
        "\n",
        "# 1つの音声にまとめる\n",
        "audio = combine_notes(\n",
        "    audio_notes,\n",
        "    notes[\"start_times\"],\n",
        "    notes[\"end_times\"],\n",
        "    notes[\"velocities\"]\n",
        "    )\n",
        "\n",
        "specplot(audio)  # スペクトログラムの表示\n",
        "play(audio, sample_rate=SR)"
      ],
      "metadata": {
        "id": "Gw7YP5tJVEI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 音声をwavデータに変換してダウンロード\n",
        "file_name = \"atashiVanpire.wav\"\n",
        "gu.save_wav(audio, file_name)\n",
        "files.download(file_name)"
      ],
      "metadata": {
        "id": "fXfo8zx2V3aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 変数 ns の中身が良い感じに使えそうなのを確認\n",
        "print(ns)"
      ],
      "metadata": {
        "id": "_cBPN6xFWKpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Polyphony RNN を使ってバッハ風の曲を作成 https://github.com/magenta/magenta/tree/main/magenta/models/polyphony_rnn\n",
        "from magenta.models.performance_rnn import performance_sequence_generator\n",
        "from magenta.models.shared import sequence_generator_bundle\n",
        "\n",
        "# モデルの初期化\n",
        "note_seq.notebook_utils.download_bundle(\"performance_with_dynamics.mag\", \"/models/\")  # Bundle（.magファイル）をダウンロード\n",
        "bundle = sequence_generator_bundle.read_bundle_file(\"/models/performance_with_dynamics.mag\")  # Bundleの読み込み\n",
        "generator_map = performance_sequence_generator.get_generator_map()\n",
        "performance_rnn = generator_map[\"performance_with_dynamics\"](checkpoint=None, bundle=bundle)  # 生成器の設定\n",
        "performance_rnn.initialize()  # 初期化"
      ],
      "metadata": {
        "id": "bY1dGgT5WTmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from note_seq.protobuf import generator_pb2\n",
        "\n",
        "total_time = 360 # 曲の長さ（秒）\n",
        "temperature = 1 # 曲の「ランダム度合い」を決める定数\n",
        "\n",
        "base_end_time = max(note.end_time for note in ns.notes)  #ベース曲の終了時刻\n",
        "\n",
        "# 生成器に関する設定\n",
        "generator_options = generator_pb2.GeneratorOptions()  # 生成器のオプション\n",
        "generator_options.args[\"temperature\"].float_value = temperature  # ランダム度合い\n",
        "generator_options.generate_sections.add(\n",
        "    start_time=base_end_time,  # 作曲開始時刻\n",
        "    end_time=total_time)  # 作曲終了時刻\n",
        "\n",
        "# 曲の生成\n",
        "gen_seq = performance_rnn.generate(ns, generator_options)\n",
        "\n",
        "note_seq.plot_sequence(gen_seq)  # NoteSequenceの可視化\n",
        "note_seq.play_sequence(gen_seq, synth=note_seq.fluidsynth)  # NoteSequenceの再生"
      ],
      "metadata": {
        "id": "Gh9m8zfNWtiG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}